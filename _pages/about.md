---
permalink: /
title: "Daniel Honerkamp"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD student at the ELLIS [Robot Learning Lab](https://rl.uni-freiburg.de/) at the University of Freiburg. My
research interests are focused on reinforcement learning, embodied AI and robotics, though much more broadly I am
interested in topics including, but not limited to, decision making, planning and multi-agent systems.

In the past I have worked across all aspects of autonomous agents and their environments. After studying economics
and working in econometric forecasting in Switzerland, I graduated on the Dean's List of the MSc Computational Statistics and Machine Learning at University College London. I then
developed novel decentralised systems and consensus protocols before I flipped the coin and started to optimise agent's behaviours within
an environment during my PhD.  

[//]: # (Note that the remainder of this site is still WIP. Until then please refer to my [google scholar]&#40;https://scholar.google.com/citations?user=Ian_c5AAAAAJ&hl=en&#41; and [university profile page]&#40;https://rl.uni-freiburg.de/people/honerkamp&#41; for recent works.)

# Publications

[Zero‑Cost Whole‑Body Teleoperation for Mobile Manipulation](http://moma-teleop.cs.uni-freiburg.de/), Daniel Honerkamp\∗, Harsh Mahesheka\∗, Jan Ole Hartz, Tim Welschehold, Abhinav Valada, arXiv preprint arXiv:2409.15095, 2024.

[Language‑Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation](http://moma-llm.cs.uni-freiburg.de/), Daniel Honerkamp\∗, Martin Büchner\∗, Fabien Despinoy, Tim Welschehold, Abhinav Valada, IEEE Robotics and Automation Letters, presentation at ICRA, 2024.

[Recent Trends in Insect and Robot Navigation through the Lens of Reinforcement Learning](https://arxiv.org/abs/2406.01501), Stephan Lochner, Daniel Honerkamp, Abhinav Valada, Andrew D Straw, Frontiers in Computational Neuroscience, 2024.

[Perception Matters: Enhancing Embodied AI with Uncertainty‑Aware Semantic Segmentation](http://semantic-search.cs.uni-freiburg.de/), Sai Prasanna\∗, Daniel Honerkamp\∗, Kshitij Sirohi\∗, Tim Welschehold, Wolfram Burgard, Abhinav Valada, Proceedings of the International Symposium on Robotics Research (ISRR), 2024.

[N\2M\2: Learning Navigation for Arbitrary Mobile Manipulation Motions in Unseen and Dynamic Environments](http://mobile-rl.cs.uni-freiburg.de/), Daniel Honerkamp, Tim Welschehold, Abhinav Valada, IEEE Transactions on Robotics (T‑RO), presentated at ICRA, 2023.

[Learning Hierarchical Interactive Multi‑Object Search for Mobile Manipulation](http://himos.cs.uni-freiburg.de/), Fabian Schmalstieg\∗, Daniel Honerkamp\∗, Tim Welschehold, Abhinav Valada, IEEE Robotics and Automation Letters (RA‑L), presentated at ICRA, 2023.

[Catch Me if You Hear Me: Audio‑Visual Navigation in Complex Unmapped Environments With Moving Sounds](http://dav-nav.cs.uni-freiburg.de/), Abdelrahman Younes\∗, Daniel Honerkamp\∗, Tim Welschehold, Abhinav Valada, IEEE Robotics and Automation Letters (RA‑L), presentated at IROS, 2023.

[Learning Long‑Horizon Robot Exploration Strategies for Multi‑Object Search in Continuous Action Spaces](http://multi-object-search.cs.uni-freiburg.de/), Fabian Schmalstieg\∗, Daniel Honerkamp\∗, Tim Welschehold, Abhinav Valada, Robotics Research, presented at ISRR, 2022.

[Active Particle Filter Networks: Efficient Active Localization in Continuous Action Spaces and Large Maps](http://apfn.cs.uni-freiburg.de/), Daniel Honerkamp, Suresh Guttikonda, Abhinav Valada, IROS Workshop on Probabilistic Robotics in the Age of Deep Learning, 2022.

[Learning Kinematic Feasibility for Mobile Manipulation through Deep Reinforcement Learning](http://kinematic-rl.cs.uni-freiburg.de/), Daniel Honerkamp, Tim Welschehold, Abhinav Valada, IEEE Robotics and Automation Letters (RA‑L), 2021.

Democratising blockchain: A minimal agency consensus model, Marcin Abram, Daniel Honerkamp, Jon Ward, Jin‑Mann Wong,
Proceedings of Tokenomics International Conference on Blockchain Economics, Security and Protocols, 2019.

# Prices and Awards

[3rd place Futureprice (”Zukunftspreis”)](https://www.stiftung-ewaldmarquardt.de/de/der_zukunftspreis/preisverleihung_2023), Ewald Marquardt Foundation, 5,000 EUR. For progress and innovation in the generation and coordination of mobile manipulation motions, 2023.

[Best Paper Award](https://mobile-manipulation.net/events/moma2022/), IROS 2022 Workshop on Mobile Manipulation and Embodied Intelligence, 2022.

[SoundSpaces Challenge - 2nd Place](https://soundspaces.org/challenge). Conference on Computer Vision and Pattern Recognition (CVPR) Embodied AI Workshop, 2022.

[SoundSpaces Challenge - 1st Place](https://soundspaces.org/challenge). Conference on Computer Vision and Pattern Recognition (CVPR) Embodied AI Workshop, 2021.

Dean’s List Award, University College London (UCL), 2018. 

[//]: # (A data-driven personal website)

[//]: # (======)

[//]: # (Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown &#40;.md&#41;, YAML &#40;.yml&#41;, HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages]&#40;https://pages.github.com/&#41; service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.)
